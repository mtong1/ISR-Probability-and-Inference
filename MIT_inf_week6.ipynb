{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEEK 6\n",
    "\n",
    "Two fundamental inference tasks in graphical models \n",
    "\n",
    "1. Marginalization: computing marginal prob table for every vertex in graph model\n",
    "2. Most probable configuration: computing most prob config of graphical model such that the configuration makes the arg max\n",
    "\n",
    "- based on assumption that conditioning has already occurred \n",
    "\n",
    "### Sum Product Algorithm / Belief Propagation\n",
    "\n",
    "- resulting algorithm in tree-structured, undirected graph models \n",
    "- distribution of x1-xn factorizes into product of node potential x product of edge potentials \n",
    "- given random variables that are values in a set X, and have a joint distribution represented by this eq:\n",
    "$$\\frac{1}{Z} \\phi_1 (x_1) \\phi_2 (x_2) \\phi_3 (x_3) \\phi_4 (x_4) \\phi_5 (x_5) \\psi_{12} (x_1,x_2) \\psi_{13} (x_1,x_3) \\psi_{14} (x_2, x_4) \\psi_{25} (x_2, x_5)$$\n",
    "\n",
    "- can compute a marginal distribution for a single variable by summing out other variables that the variable depends on \n",
    "    - ex: \n",
    "    $$p_{x_1}(x_1) = \\sum_{x_2} \\sum_{x_3} \\sum_{x_4} \\sum_{x_5} p_{X_1...X_2}(x_1,...,x_n) $$\n",
    "\n",
    "- take all terms relying on each sum and rearrange until it works for ex: \n",
    "$\\sum_{x_5} \\phi_5 (x_5) \\psi_{25}(x_2,x_5)$ is all the five terms grouped under sum of 5 \n",
    "- that summation can actually be represented as $m_{5->2}(x_2)$ where $m-{5->2}$ indicates node 5 depending on 2 and x_2 the node \n",
    "\n",
    "- general algorithm: \n",
    "- req: MUST be a tree \n",
    "1. choose root node, identify leaf nodes \n",
    "2. start from leaf nodes going up to root node, and compute required messages at each step \n",
    "3. after reaching root node, go back down through leaf nodes and calculate messaes as you go \n",
    "\n",
    "$$m_{i->k}(x_j) = \\sum_{x_i} [\\phi_i (x_i) \\psi_{i,j}(x_i,x_j) \\Pi_{k \\epsilon N(i)} m_{k->i}(x_i)] $$ \n",
    "where k \\epsilon N(i) such that k!=j and N(i) denotes neighboring nodes of node i in the graph \n",
    "\n",
    "marginal distrib: $p_{x_i}(x_i) = \\frac{1}{Z} \\phi_i (x_i) \\Pi_{j \\epsilon N(i)}m_{j->i}(x_i)$\n",
    "- typically, the RHS is computed using unnormalized table P_x_i and THEN normalizing after \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models \n",
    "- where we have hidden states x_1...x_n and inferred given observations y1...yn\n",
    "\n",
    "- forward backward algorithm \n",
    "    - finds conditional distribution over hidden states given data \n",
    "CONFUSION \n",
    "- point is to get good estaimates for x1-xn\n",
    "- using unnormalized probabilities, is proportional to but not equal to the probability (1) bc it is unnormalized \n",
    "\n",
    "2nd page \n",
    "- often, HMMs modeled with prior distribution, transition model, and observation model (p_X, p_X_(i+1)|X_i, p_(Y_i | X_i))\n",
    "- transitional distrib: describes distribution for next state given current state, represented as matrix (ex: A) $p_{X_k+1 | X_k} (x_{k+1 | x_k})$ \n",
    "    - is always row = curr state, column = prob for next state \n",
    "- observation distrib: distrib for output given the current state as matrix (ex: B) $p_{y_k | X_k} (y_k | x_k)$\n",
    "- init state distrib: starting distrib over states, rep as vector pi_0 $p_{x_1} (x_1)$\n",
    "\n",
    "### Formulating HMMs \n",
    "\n",
    "- each row of transitional would represent our current state, and each value in the columns/spaces of each array is the probabilities of next state occurring \n",
    "- observation matrix would be row = curr state and observations = columns \n",
    "    - probabilities of observing something in each curr state \n",
    "- initial state distrib is a vector, each space is a curr state and probability for that state at initial start \n",
    "\n",
    "### Forward/Backward Messages for HMMs \n",
    "$$\\alpha_{1->2} = \\sum_{x_1}\\alpha_{0->1}(x_1)\\phi(x_1)\\psi(x_1,x_2)$$\n",
    "\n",
    "outputs should have as many possibilities as numbers of values for states\n",
    "(QUESTION HERE: why only for each value of x_2? or is this an example specific message)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
