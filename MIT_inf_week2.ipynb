{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comp_prob_inference\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Relating Two Random Variables \n",
    "\n",
    "- joint probability table: can do table representation of two random variable relation by putting each variable on diff axis/side of the table, denoted by P_t,w (where t and w are the random variables)\n",
    "    - t and w are said to be \"jointly distributed\"\n",
    "\n",
    "- finding probability of a variable happening given another variable is set can be tricky\n",
    "\n",
    "![title](images/week2_2vargraph.png)\n",
    "\n",
    "- ex: finding the probability of temperature given that W = rainy? \n",
    "    - can't just say its 1/30 + 2/15 or that the prob space is that since it doesn't add up to 1\n",
    "    - rather, we normalize it by dividing by what that adds up to in the broader table \n",
    "    - they add up to 1/6, so divide each value by 1/6 to find its value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing a Joint Probability Table in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 1: not an actual table, but stores the info \n",
    "prob_table = {('sunny', 'hot'): 3/10,\n",
    "    ('sunny', 'cold'): 1/5,\n",
    "    ('rainy', 'hot'): 1/30,\n",
    "    ('rainy', 'cold'): 2/15,\n",
    "    ('snowy', 'hot'): 0,\n",
    "    ('snowy', 'cold'): 1/3}\n",
    "\n",
    "# accessing W = rainy and T = cold\n",
    "prob_table[('rainy', 'cold')]\n",
    "\n",
    "# METHOD 2: dictionaries within dictionaries, doesn't have any specific ordered rows/columns like the table \n",
    "\n",
    "prob_W_T_dict = {}\n",
    "for w in {'sunny', 'rainy', 'snowy'}:\n",
    "    prob_W_T_dict[w] = {}\n",
    "\n",
    "prob_W_T_dict['sunny']['hot'] = 3/10\n",
    "prob_W_T_dict['sunny']['cold'] = 1/5\n",
    "prob_W_T_dict['rainy']['hot'] = 1/30\n",
    "prob_W_T_dict['rainy']['cold'] = 2/15\n",
    "prob_W_T_dict['snowy']['hot'] = 0\n",
    "prob_W_T_dict['snowy']['cold'] = 1/3\n",
    "\n",
    "comp_prob_inference.print_joint_prob_table_dict(prob_W_T_dict)\n",
    "\n",
    "# accessing W = rainy and T = cold\n",
    "prob_W_T_dict['rainy']['cold']\n",
    "\n",
    "# METHOD 3: 2D Array, separate lists that are ordered to correspond to each other\n",
    "import numpy as np\n",
    "prob_W_T_rows = ['sunny', 'rainy', 'snowy']\n",
    "prob_W_T_cols = ['hot', 'cold']\n",
    "prob_W_T_array = np.array([[3/10, 1/5], [1/30, 2/15], [0, 1/3]])\n",
    "comp_prob_inference.print_joint_prob_table_array(prob_W_T_array, prob_W_T_rows, prob_W_T_cols)\n",
    "\n",
    "# accessing W = rainy and T = cold\n",
    "prob_W_T_array[prob_W_T_rows.index('rainy'), prob_W_T_cols.index('cold')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalization\n",
    "\n",
    "- summarizing randomness\n",
    "- given two random variables X and Y that have a joint probability table $p_{x,y}$, for any x that $\\in$ X, the marginal probability that X = x is given by this summation equation\n",
    "$$p_X(x) = \\sum_{y} p_{X,Y}(x,y)$$\n",
    "- recall the above example of being sunny, rainy, and snowy while also hot or cold \n",
    "- given each intersection has a different probability, we can sum up the \"hot\" and \"cold\" probabilities for each row to get a total probability \n",
    "- ex: p(sunny,hot) = 3/10 and p(sunny,cold) = 1/5, p(sunny) = 1/2\n",
    "p(w) is called marginal distribution of W \n",
    "- typical way to calculate this: \n",
    "$$p_w(w)=\\sum_{t\\in \\tau} p_{w,t}(w,t)$$\n",
    "\n",
    "where $\\tau$ is the set of values that random variable T can take on. The above equation is more often written as:\n",
    "$$p_w(w) = \\sum_{t} p_{w,t}(w,t)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Marginalization\n",
    "\n",
    "prob_table_WI = {('sunny','1'):1/2,\n",
    "              ('sunny','0'):0,\n",
    "              ('rainy','1'):0,\n",
    "              ('rainy','0'):1/6,\n",
    "              ('snowy','1'):1/3,\n",
    "              ('snowy','0'):1/3}\n",
    "\n",
    "prob_table_XY = {('sunny','1'):1/4,\n",
    "                ('sunny','0'):1/4,\n",
    "                ('rainy','1'):1/12,\n",
    "                ('rainy','0'):1/12,\n",
    "                ('snowy','1'):1/6,\n",
    "                ('snowy','0'):1/6}\n",
    "\n",
    "prob_table_X = {('sunny'):1/2,\n",
    "                ('rainy'):1/6,\n",
    "                ('snowy'):1/3}\n",
    "\n",
    "prob_table_Y = {('1'):1/2,('0'):1/2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalization for Many Random Variables\n",
    "\n",
    "- when having multiple random variables, our joint probability table becomes multi-dimensional\n",
    "- ex: with a 3 var table, if we were to marginalize one variable, the resulting probability distribution would be a 2d table still \n",
    "- if we wanted to marginalize two of the 3 variables, resulting equation for one example variable is as follows:\n",
    "$$p_X(x) = \\sum_{X,Y}p_{X,Y}(x,y) = \\sum_{y}(\\sum_{z}p_{X,Y,Z}(x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning for Random Variables\n",
    "- conditioning: randomness of a variable given that another variable takes on a specific value \n",
    "- $p_{T|W}(cold | rainy)$ = probability of cold given rainy is set\n",
    "- when doing so, make sure to normalize the probability according to what distribution you have \n",
    "\n",
    "QUESTION what is conditioning helpful for? what makes it diffrent from marginalization?\n",
    "- conditional probability of event X =x given Y = y is described by this equation\n",
    "$$p_{X,Y}(x,y) \\triangleq p_{X,Y}(x,y)/p_Y(y)$$\n",
    "\n",
    "- essentially dividing the probability of the two events by the sum of that total variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12298276623950503"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpsons_paradox_data import *\n",
    "\n",
    "# ex: to access female C admitted probability\n",
    "joint_prob_table[gender_mapping['female'], department_mapping['C'], admission_mapping['admitted']]\n",
    "\n",
    "# to marginalize with numpy, we sum across axis 1 (in this case, department axis)\n",
    "joint_prob_gender_admission = joint_prob_table.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpson's Paradox\n",
    "\n",
    "A real life application where a school was accused of disproportionately biasing gender when admitting students to the school\n",
    "\n",
    "Let's say we want to find the probability that a woman applies and is admitted. Since we have three axes to our data (gender, department, and acceptance status), we need to abstract department away. This is done by marginalizing the department variable away. Then, we need to do a conditional probability: the probability that a person is admitted given that they are a woman \n",
    "\n",
    "$$p_{A,G} (admitted | female) = \\frac{p_{A,G}(admitted,female)}{p_G(female)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admitted': 0.3033351498637601, 'rejected': 0.6966648501362399}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3033351498637601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of female and admitted \n",
    "joint_prob_gender_admission[gender_mapping['female'], admission_mapping['admitted']] \n",
    "\n",
    "# finding probability of female\n",
    "female_only = joint_prob_gender_admission[gender_mapping['female']]\n",
    "# normalizing it \n",
    "prob_admission_given_female = female_only / np.sum(female_only)\n",
    "\n",
    "# turning this new conditional table into a dict format\n",
    "prob_admission_given_female_dict = dict(zip(admission_labels, prob_admission_given_female))\n",
    "print(prob_admission_given_female_dict)\n",
    "\n",
    "prob_admission_given_female_dict['admitted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44519509476031227"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_only = joint_prob_gender_admission[gender_mapping['male']]\n",
    "\n",
    "prob_male = male_only/np.sum(male_only)\n",
    "\n",
    "prob_male_dict = dict(zip(admission_labels, prob_male))\n",
    "prob_male_dict['admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SYNTAX NOTE: when conditioning something that is NOT on the 0th axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'female': 0.3172274654630008, 'male': 0.6827725345369992}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8200000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the : is to indicate that we want to keep everything in the 0th axis\n",
    "admitted_only = joint_prob_gender_admission[:, admission_mapping['admitted']]\n",
    "\n",
    "# probability of gender given admitted \n",
    "prob_gender_given_admitted = admitted_only / np.sum(admitted_only)\n",
    "prob_gender_given_admitted_dict = dict(zip(gender_labels, prob_gender_given_admitted))\n",
    "print(prob_gender_given_admitted_dict)\n",
    "\n",
    "# conditioning in admitted and gender \n",
    "female_and_A_only = joint_prob_table[gender_mapping['female'], department_mapping['A']]\n",
    "\n",
    "# probabilities of admitted given gender is female and deparment is A\n",
    "prob_dg = joint_prob_table[gender_mapping['female'], department_mapping['A']]\n",
    "\n",
    "restricted = prob_dg/ np.sum(prob_dg)\n",
    "restricted = dict(zip(admission_labels,restricted/np.sum(restricted)))\n",
    "restricted['admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning on Events\n",
    "\n",
    "- somewhat of a zooming in \n",
    "- given a probability space $\\Omega$, there may be two events inside called A and B, and an intersection between them\n",
    "- if we choose to observe event A, for ex, we can go from p($\\omega$,p) --> p(a,p(.|a)) where probability of omega is now conditioned on a\n",
    "    - when we find overall probability of a now, its the probability of a combined w probability of some event given a \n",
    "    - we have to normalize each time for this case, since A's probability is still taken in terms of $\\Omega$\n",
    "\n",
    "product rule: when finding the conditional probability, can also model it as A interesct B event probability\n",
    "--> $ P(A)*P(B|A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Theorem for Events \n",
    "\n",
    "- foundational for inference\n",
    "- recall the formulas we found for conditional probability (P(a intersect b)/p(b)) and for p(a intersect b) (which is p(a)p(b|a))\n",
    "- if we plug in the equation for a intersect b into the original conditional probability equation, we get bayes' theorem \n",
    "\n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)} $$\n",
    "\n",
    "This is useful because it makes it easier to find conditional probabilities since we know these smaller terms more easily \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Law of Total Probability\n",
    "\n",
    " - we can break down probability spaces into sections/pieces to find the probability of an event in a space \n",
    "\n",
    " $$P(A) = \\sum{i=1}^{n} P(A \\cap B_i)$$\n",
    "\n",
    " where B1...Bn represents disjoint partitions that make up $\\Omega$\n",
    "\n",
    " and A is a probability that is splayed across these partitions \n",
    "\n",
    " finding P(A) is the same as finding the sum of the intersect of A given B1...Bn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conditional distribution function ? !!\n",
    "\n",
    "Random Variables Conditioned on Events\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
